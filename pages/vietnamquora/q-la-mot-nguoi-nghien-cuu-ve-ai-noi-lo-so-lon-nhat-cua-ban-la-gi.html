<div>936<br><br>#AI #hypothesisScenario #potentialThread #vmc<br><br>Q: Là một người nghiên cứu về AI, nỗi lo sợ lớn nhất của bạn là gì?<br><br>A: Sridhar Mahadevan, Thành viên AAAI<br><br>L: 1500 word<br><br>========<br> <br>Người cộng sự lâu năm của tôi, một trong những nhà tri thức sâu sắc nhất về AI, Stuart Russell, mới trả lời về câu hỏi này dưới dạng một cuốn sách đấy.<br><br>[Human Compatible:[](https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS/ref=mp_s_a_1_1?keywords=stuart+russell&qid=1572923399&sr=8-1) Artificial Intelligence and the Problem of Control, Stuart Russell](https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS/ref=mp_s_a_1_1?keywords=stuart+russell&qid=1572923399&sr=8-1)<br><br>Rất đáng để đọc toàn bộ những phần thảo luận kích thích tư duy của ông. Song tôi sẽ cố gắng tổng kết những luận điểm cơ bản ông đưa ra. Ông bắt đầu với việc viện dẫn một tình huống giả tưởng trong đó một nhóm các nhà phê bình văn học được yêu cầu tưởng tượng ra một tình huống mà một người trong số họ đã thực sự được coi là đúng. Suy nghĩ này chưa bao giờ xảy đến với họ bởi lẽ những cuộc chiến về tri thức với đối thủ là động lực thôi thúc lớn lao của họ.<br><br>Theo cách tương tự, người nghiên cứu về AI lâu năm như Stuart và tôi, miệt mài trong bốn thập kỷ liền, luôn luôn bận tâm với thách thức làm cho máy móc trở nên thông minh hơn tới mức bọn tôi còn chẳng thèm đặt ra câu hỏi quan trọng hơn thế: nếu như chúng tôi thực sự thành công thì sao?<br><br>Cứ ngưng lại một lúc đã, đặt cốc cafe của bạn xuống, tháo tai nghe ra, tạm thời một lúc thôi đã. Và một lần nữa, hãy tự hỏi chính mình: nếu AI là một thành công thì sao? Tất nhiên, như Stuart đã nói thì, đó sẽ là sự kiện lớn nhất trong quá trình khoa học và công nghệ hiện tại: việc tạo ra được những chủng loại siêu thông minh, thậm chí hơn cả chúng ta, và cực kỳ quyền năng theo rất nhiều cách khác nhau.<br><br>Và cũng theo cách đó, Stuart yêu cầu bạn tưởng tượng ra việc nhân loại nhận được một email từ người ngoài hành tinh nói rằng: CHÚNG TÔI SẼ TỚI TRONG VÒNG 30 NĂM NỮA ĐẤY! Chúng ta sẽ phản ứng thế nào nhỉ? Địa ngục sẽ là một cách nói khá nhẹ đấy. Nỗi sợ hãi lớn nhất của chúng ta có thể sẽ trở thành hiện thực. Hành tinh này sẽ bị những kẻ lạ mặt có sức mạnh và ý định chưa rõ ràng xâm chiếm.<br><br>Thực tế thì, đó chính là tình thế hiện tại của chúng tôi đấy. Lấy một ví dụ khá cụ thể thì, người sáng lập ra Open AI, Sutskever, một nhà khoa học deep learning rất có tiếng, gần đây đã dự đoán rằng có khả năng AGI (AI rộng - thành thạo nhiều lĩnh vực khác nhau, trái với AI hẹp) sẽ được tạo ra trong khoảng thời gian khá ngắn ngủi là 5 năm tới!<br><br>[https://link.medium.com/SmB7Rijfm1](https://link.medium.com/SmB7Rijfm1)<br><br>Tất nhiên, không phải ai cũng được tự tin như thế. Tôi không chắc rằng chính deep learning sẽ đưa tình cảnh đấy. Nhưng đó vẫn chỉ là dự đoán của tôi mà thôi. Những người khác tin rằng sẽ có AGI, song sẽ phải còn lâu nữa.<br><br>[This is when AI’s top researchers think artificial general intelligence will be achieved](https://www.google.com/amp/s/www.theverge.com/platform/amp/2018/11/27/18114362/ai-artificial-general-intelligence-when-achieved-martin-ford-book)<br><br>Giờ đây, vấn đề mấu chốt là không ai nghĩ rằng AI sẽ thất bại ấy cả. Câu hỏi ở đây chỉ là *khi nào*, chứ không phải là *liệu.* Theo nhiều cách thì, đó thực sự là một viễn cảnh đáng sợ. Tại sao à? Bởi lẽ chúng ta không biết liệu rằng máy móc thực sự thông minh sẽ hành động ra sao. Liệu chúng ta có khả năng kiểm soát chúng không? Liệu chúng có làm việc vì lợi ích của chúng ta không? Liệu chúng ta có trở thành những kẻ thừa không? Những câu hỏi này nên được coi là quan trọng giống như việc kiểm soát vũ khí hạt nhân trong thế kỷ 20. Các quốc gia đã cố gắng hết mức để đảm bảo rằng công nghệ hạt nhân đã bị giới hạn. Gần như tất cả các nước đã ký hiệp ước không phổ biến.<br><br>Chẳng có hoạt động tương tự nào đối với AI. Chẳng có ai đang đặt ra những câu hỏi khó ấy cả. Có lẽ Stuart là người nghiên cứu AI đầu tiên muốn giơ tay mình và nói: này, chờ một phút đã! Có lẽ chúng ta đang cố gắng chế tạo thứ gì đó sẽ tạo nên cái kết cho loài người đấy. Chúng ta nên suy xét lại điều này. Liệu rằng có cách nào đó để chúng ta đảm bảo được rằng hệ thống AI sẽ hoạt động vì lợi ích của loài người hay không? Rằng chúng sẽ là công cụ của cái thiện chứ không phải cái ác.<br><br>Tương tự, hãy nghĩ về những chiếc tàu hỏa lệch đường do những mạng xã hội lớn đại diện mà xem. Chúng dễ dàng bị thao túng biết chừng nào và tại nhiều nước, các mạng xã hội đó bị lợi dụng để trở thành công cụ thực hiện việc thanh lọc sắc tộc, gian lận bầu cử, hành hình những người phụ nữ vô tội bằng cách cáo buộc trắng trợn rằng họ là phù thủy, cổ vũ cho những gã sát nhân hàng loạt và cả những thứ tệ hơn nữa. Chẳng có chuyện nào trong số đó có được ngay từ đầu cả. Người sáng lập ra các nền tảng đó đã không cổ súy những hành động kia. Ý định của họ hiển nhiên rất đáng tự hào mà. Song, dù sao thì những chuyện đó vẫn xảy ra mà thôi.<br><br>Tương tự, những người nghiên cứu AI như Stuart và tôi hi vọng rằng chẳng có nghiên cứu nào của mình có thể bị lợi dụng vào những mục đích bất chính như vậy. Nhưng liệu chúng ta có thể đảm bảo được điều đó không nhỉ? Đáng buồn là không. Cuốn sách của Stuart là một luận điểm rất dài kêu gọi cộng đồng AI hãy nghĩ lại trước khi quá muộn, đồng thời phác họa được một cách thức để đảm bảo rằng những hệ thống AI vẫn “tương thích với con người”.<br><br>Liệu rằng việc làm này đã là quá muộn hay chưa? Liệu có ai thèm lắng nghe không nhỉ? Stuart đã nêu ra ý tưởng để phản bác lại những người nói rằng nỗi sợ đó đã bị phóng đại một cách quá đáng bằng việc tưởng tượng ra rằng một người nghiên cứu AI như ông và tôi đang lái một chiếc xe bus chở toàn bộ nhân loại lao đến một vách núi, và xoa dịu các hành khách bằng cách nói rằng chiếc xe sẽ hết xăng trước khi nó đi được đến vách núi đó. Liệu bạn có tin tưởng chúng tôi không?<br><br>Đó là nỗi sợ lớn nhất của tôi đấy. Ấy là chúng tôi sẽ thành công. Là chúng tôi sẽ tạo ra một thứ mà mình chẳng thể kiểm soát nổi. Einstein đã viết một bức thư rất nổi tiếng gửi cho Roosevelt trong Thế Chiến thứ hai kêu gọi Roosevelt tạo ra một nhà máy nhằm thúc đẩy nhanh sự phát triển của vũ khí nguyên tử. Ông và những nhà vật lý tri thức khác hiểu rõ mối đe dọa to lớn có thể có nếu như Hitler có thể sở hữu những vũ khí như vậy. Cuối cùng thì, dự án Manhattan do những nhà vật lý tài năng chỉ đạo đã thành công trong việc tạo ra những loại vũ khí như vậy. Sau đó Einstein đã hối hận tới mức cùng cực về vai trò của mình trong nỗ lực này, đồng thời nói rằng ông ước mình có thể  đốt đôi bàn tay mình đi nếu cứu vãn được mọi chuyện.<br><br>Cuốn sách của Stuart là một lời nhắc nhở đúng lúc rằng, sự phát triển của công nghệ mạnh mẽ như AI sẽ luôn luôn là một con dao hai lưỡi. Trừ khi chúng ta đang tạo ra một chủng loại khác, một thứ có thể sở hữu sức mạnh thống trị tất cả mọi người.<br><br>Các engine tìm kiếm web truy cập được vào nhiều dữ liệu hơn những gì bất kỳ con người nào có thể đọc trong cả một triệu cuộc đời đấy. Hãy tưởng tượng xem chuyện gì sẽ xảy ra nếu chúng hiểu được những gì đang được đọc. Sau đó thì sao? Chúng có rủ lòng từ bi không? Lịch sử của trái đất này sẽ ủng hộ điều ngược lại đấy. Mọi chủng loài, kể cả chúng ta nữa, đã có được uy quyền bằng cách hủy diệt đối thủ của mình. Tại sao những hệ thống AI siêu thông minh lại phải hành xử khác đi nhỉ?<br><br>Thực sự có quá nhiều điều để nghĩ.<br><br>[[SOURCE]](https://www.quora.com/As-an-A-I-researcher-what-is-your-biggest-fear/answer/Sridhar-Mahadevan-6)<br><br><img src='https://scontent.fhan17-1.fna.fbcdn.net/v/t1.6435-9/74632535_2511147229131830_8608001092757749760_n.jpg?stp=dst-jpg_s720x720&_nc_cat=104&ccb=1-7&_nc_sid=ca434c&_nc_ohc=YxOTgYGbUXgAX_iRQ6P&_nc_ht=scontent.fhan17-1.fna&edm=AFuVL-cEAAAA&oh=00_AfBsVHJ8cFh8lluenQJgxsjx0qX0b2M2ssdk3WOEJ8rdyw&oe=63D0DA14'></div>