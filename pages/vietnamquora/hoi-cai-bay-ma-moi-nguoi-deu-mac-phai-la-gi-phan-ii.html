<div>42<br>#life #vmc<br>Hỏi: Cái bẫy mà mọi người đều mắc phải là gì (phần II) ?<br>Trả lời: Shanks Wang<br>.<br>Hãy tưởng tượng rằng bạn đang ở tương lai 50 năm tới. Bạn đến một sự kiện bán xe để mua chiếc ô tô tự lái đầu tiên của mình.<br>.<br>Những chiếc xe này sẽ cách mạng hóa an toàn đường bộ, có tốc độ phản ứng tốt hơn và khả năng ra quyết định đến từng tích tắc so với một người lái xe thông thường.<br>.<br>Tuy nhiên, đại lý bán hàng đã giải thích với bạn rằng trong trường hợp vô cùng hiếm, khi một tai nạn không thể tránh khỏi xảy ra, nó sẽ hy sinh chính bản thân bạn như là người ngồi trên xe nếu nó có thể cứu được nhiều người hơn và giảm thiểu tối đa các tổn thất về sinh mạng.<br>.<br>Ví dụ, một ngày nào đó, trong khi bạn đang lái xe, một sự kiện không may xảy ra khiến chiếc xe lao về phía một đám đông 10 người đang băng qua đường. Nó không thể dừng lại kịp được, do đó, nó sẽ tránh việc giết chết 10 người kia bằng cách bẻ lái đâm vào một bức tường, đồng thời giết chết bạn quá trình ấy.<br> .<br>Bạn tỏ vẻ như, "đậu móa, tôi lượn đây". Và bạn bỏ đi mà không mua chiếc xe đó.<br>.<br>Bạn thấy đó, đây là tình trạng tiến thoái lưỡng nan về mặt đạo đức của chiếc xe tự lái[1].<br>.<br>Các nhà nghiên cứu đã thực hiện các cuộc thăm dò ý kiến [2] đối với nhiều người về các kịch bản đạo đức khác nhau khi nói đến những chiếc xe tự lái. Các kết quả rất thú vị, nếu có thể dự đoán được. Nói chung, mọi người cảm thấy thoải mái với ý tưởng rằng xe tự lái nên được lập trình để giảm thiểu số người chết.<br>.<br>Tuy nhiên, thực sự họ lại muốn những người khác đi trong những chiếc xe tự động ấy, nhiều hơn là muốn tự mình mua những chiếc xe tự lái ấy.<br>.<br>Mọi người đang ủng hộ những chiếc xe hi sinh mạng sống người trên xe để cứu sống những người khác - chừng nào họ không phải tự mình lái một chiếc xe như vậy.<br>.<br>Do đó, bằng cách sử dụng một AI (trí thông minh nhân tạo - nd) nhằm giảm thiểu thiệt hại trên đường đi, điều ngược lại có thể xảy ra vì ít người sẽ mua những chiếc xe tự lái này, từ đó dẫn đến nhiều tai nạn trên đường hơn bởi con người lái xe (theo thống kê, nếu AI lái thì 10 triêu km mới có một vụ tai nạn thay vì 100 000 km nếu là người lái - nd).<br>.<br>Trên thực tế, không khó để thấy rằng thay vào đó nếu chiếc xe AI được lập trình để để bảo vệ chủ sở hữu của nó một cách ích kỷ bằng mọi giá, ta sẽ cứu được nhiều mạng sống hơn vì nhiều người sẽ sẵn sàng mua những chiếc xe này! Một ý tưởng khá phản trực giác.<br>________________________________________<br>Đây là một trường hợp tương tự khác.<br>.<br>Chúng ta đều biết về các nhà hoạt động vì quyền lợi động vật và cuộc chiến chống lại các thử nghiệm trên động vật đúng không?<br>.<br>Lập luận của họ có vẻ như có ý nghĩa:<br>.<br>Những con vật không thể đưa ra được ý kiến. Con người thì có thể. Chừng nào mà những người trưởng thành đồng ý với các thí nghiệm này, thì đó là một tình huống đôi bên cùng có lợi. Đã có các người tình nguyện viên để thử nghiệm lâm sàng các loại thuốc, vậy tại sao không dùng con người hẳn luôn?<br>.<br>Bây giờ, chúng ta hãy nhìn vào các bước thực sự trong việc phát triển loại thuốc mới [3]:<br>.<br>Thấy các thử nghiệm tiền lâm sàng chứ? Đó là khi chúng tôi thử nghiệm thuốc trên động vật trong cơ thể hoặc trong ống nghiệm để đánh giá độ an toàn, độc tính và hiệu quả của nó. Như bạn thấy, 60-70% thuốc mới được phát hiện đã được loại bỏ vì chúng bị coi là không an toàn. Những thử nghiệm trên con người chỉ diễn ra sau đó.<br>.<br>Chính những người chống lại các thí nghiệm trên động vật lại là những người không sẵn sàng làm những chú chuột bạch đầu tiên để thay thế các con vật này, cũng giống như trường hợp của những chiếc xe tự lái.<br>.<br>Bây giờ, rõ ràng là những hành động phi đạo đức và sự độc ác không cần thiết đối với động vật thí nghiệm phải bị trừng trị. Đó là một suy nghĩ phổ biến. Tôi thậm chí không biết tại sao tôi cảm thấy cần phải đưa ra lời từ chối này.<br>.<br>Nhưng tôi có thể nói, không chút nghi ngờ, nếu tất cả các thử nghiệm trên động vật đều bị cấm thì sẽ không có đủ người tình nguyện viên để tới được bất cứ giai đoạn nào gần với việc có được nghiên cứu chính xác.<br>.<br>Kết quả là nhiều loại thuốc trên thị trường sẽ không an toàn, chúng sẽ gây hại nhiều hơn là có lợi. Và chúng ta đang nói về những thiệt hại ảnh hưởng đến hàng triệu người trên toàn cầu.<br>________________________________________<br>Vậy đạo đức của câu chuyện này là gì?<br>.<br>Luân thường và đạo lý không phải lúc nào cũng rõ ràng trắng đen. Cái "bẫy" lớn nhất mà người ta mắc vào, là nghĩ rằng họ là những người tốt, đơn giản chỉ vì họ muốn làm điều tốt.<br>.<br>Xin lỗi vì đã làm bạn vỡ mộng, nhưng có ý định tốt không có nghĩa là bạn đang thực sự làm tốt. Đặc biệt là nếu những ý định tốt đó được tạo ra từ lý luận tình cảm. Bạn không có tầm nhìn của bức tranh lớn, và chỉ có được tầm nhìn trong đường hầm, như thể nhìn ra từ đáy của một cái giếng.<br>.<br>Thật đáng buồn, không phải mọi người đều hiểu điều này.<br>.<br>Để một xã hội phát triển, những người này không được phép có vị trí quan trọng, nơi họ có thể đưa ra quyết định cho người dân.<br>.<br>Note:<br>- Đọc bài viết lại liên tưởng đến câu chuyện làm từ thiện ở Việt Nam mình. Giải Nobel Kinh tế năm 2015 nói rằng nếu bạn càng viện trợ cho những nước nghèo thì chỉ càng duy trì tình trạng nghèo đói ấy mà thôi. Xét về lâu dài, người có lợi nhất chỉ có chính quyền!<br>.<br>Link tham khảo: <br>[1] Why Self-Driving Cars Must Be Programmed to Kill<br>https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/#comments<br>.<br>[2] [1510.03346] The social dilemma of autonomous vehicles<br>https://arxiv.org/abs/1510.03346<br>.<br>[3] Clinical Trials | PhRMA<br>http://www.phrma.org/advocacy/research-development/clinical-trials<br><br>Bài viết:<br>https://www.quora.com/What-is-life%E2%80%99s-biggest-trap-people-fall-into/answer/Shanks-Wang<br><br><img src='https://scontent.fhan17-1.fna.fbcdn.net/v/t1.18169-9/22728765_1990078304572061_2676663567631090559_n.jpg?_nc_cat=109&ccb=1-7&_nc_sid=07e735&_nc_ohc=BHEhAxf7JooAX8hE0Pb&_nc_ht=scontent.fhan17-1.fna&edm=AFuVL-cEAAAA&oh=00_AfAD-YRinD7QPXDPWPx7Nw-pZDCzqZeExI8nJXt0yE7tQA&oe=63D0C8D9'></div>