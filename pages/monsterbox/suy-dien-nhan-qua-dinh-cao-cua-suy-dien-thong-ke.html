<p>[English Below]</p><p> SUY DIỄN NHÂN QUẢ - ĐỈNH CAO CỦA SUY DIỄN THỐNG KÊ? </p><p> Xác suất thống kê (XSTK) tương đối “kỳ diệu”, vì hiện tại đang là công cụ cho nhiều ngành khoa học (bao gồm cả khoa học tự nhiên và khoa học xã hội), đặc biệt là nền tảng của các công nghệ mới thời 4.0 như AI, Big Data hay Machine Learning. Tuy vậy, sự kỳ diệu của phát minh khoa học nào đó vẫn thường trở nên vô dụng (hay thậm chí có hại) do cách sử dụng sai lệch của con người, đặc biệt điều này lại thường xuyên xảy ra với những thứ phổ biến như XSTK.</p><p> Vì mặc dù XSTK kỳ diệu thật, nhưng việc ứng dụng nó tương đối phức tạp, cũng như có những giới hạn cụ thể (chứ không thể dễ dãi dùng để đưa ra các kết luận tổng quát). Ở bài viết gần nhất về XSTK, chúng tôi có nhắc đến sự phức tạp của việc đưa ra các dự báo hay suy luận từ số liệu thống kê do rất khó xác định được tất cả các biến số có thể ảnh hưởng đến kết quả cuối cùng, cũng như mối quan hệ và mức độ ảnh hưởng của chúng. Trong số những thứ phức tạp tôi vừa liệt kê, có một yếu tố quan trọng là “mối quan hệ giữa các biến số”.</p><p> Trong XSTK, khi xem xét hai biến, người ta thường dùng mối quan hệ tương quan (correlation) để xem xét mối quan hệ giữa các biến ngẫu nhiên. Chẳng hạn, khi xem xét hai dữ liệu, (1) “lượt like fanpage Monster Box” và (2) “GDP bình quân của Việt Nam”, nếu chúng có đồ thị tăng trưởng tương đồng (tất nhiên phải qua rất nhiều công thức toán học phức tạp), có thể kết luận rằng hai biến này tương quan với nhau.</p><p> Tuy vậy, bất kể hai biến tương đồng đến mức nào đi chăng nữa, không có nghĩa rằng biến A đã tác động đến biến B và ngược lại. Hay nói cách khác, việc lượt like Monster Box tăng đồng thời với GDP Việt Nam, không có nghĩa rằng Monster Box giúp Việt Nam tăng trưởng kinh tế.</p><p> Không phải ngẫu nhiên, các nhà thống kê học có một cảnh báo kinh điển: “Mối quan hệ Tương quan không bao hàm quy luật Nhân quả” (Correlation does not imply Causation) [1]. Vậy…</p><p> 1.    Suy diễn Nhân quả (Causal Inference) là gì?</p><p> Khi sự vật, sự kiện, quá trình, trạng thái này góp phần tạo ra sự vật, sự kiện, quá trình, trạng thái kia… ta có thể nói rằng đã có sự xuất hiện của quan hệ nhân quả. Nhìn chung, quan hệ nhân quả có thể hiểu theo hướng common sense: cái này là nguyên nhân của cái kia.</p><p> Trong XSTK, “suy diễn nhân quả (causal inference)” là quá trình tìm các kết luận cho thấy sự tồn tại của mối quan hệ nguyên nhân và hệ quả (cause – effect) ấy giữa các biến, dựa trên các điều kiện xảy ra của biến hệ quả [2]. Các nghiên cứu về “suy diễn nhân quả” bắt đầu phát triển mạnh mẽ từ thập niên 80 và ảnh hưởng đến nhiều lĩnh vực như triết học, giáo dục, thống kê, khoa học máy tính, khoa học sức khỏe, dịch tễ, chính sách công và kinh tế học.</p><p> Tuy nhiên, phải đến năm 2000 khi Judea Pearl xuất bản cuốn “Causality: Models, Reasoning, and Inference”, nền tảng lý thuyết và các công cụ toán học để thực hiện “suy diễn nhân quả” mới được thống nhất và hoàn thiện [3]. </p><p> Trong bài viết kỳ trước, chúng tôi có nói về việc sử dụng dữ liệu thống kê để “biết những gì đã diễn ra và dự đoán những gì sẽ xảy đến bằng cách quan sát các biến số và rút ra mối quan hệ giữa chúng, từ đó dự báo khả năng xuất hiện hoặc xảy đến của một biến cụ thể trong tương lai”. Dù rất hay và hữu ích nhưng hướng ứng dụng này vẫn đang dừng lại ở tầng thấp nhất trong hệ thống 3 bậc “suy diễn nhân quả” của Judea Pearl. Cụ thể, theo quan điểm của Pearl, các nghiên cứu về “suy diễn nhân quả” phải trả lời được 3 dạng câu hỏi tương ứng với 3 tầng nhận thức của con người từ đơn giản tới phức tạp, mà ông gọi là “the Ladder of Causation (tạm dịch: Thang nhân quả) [4]. Thang nhân quả này bao gồm:</p><p> -   Tầng tương quan (Association): “Nếu tôi quan sát được X thì Y sẽ thay đổi như thế nào?”.</p><p> -   Tầng hành động can thiệp (Intervention): “Nếu tôi thực hiện X thì Y sẽ thay đổi như thế nào?”.</p><p> -   Tầng giả định phản thực (Counterfactuals): “Nếu tôi đã thực hiện X thì Y đã có thể thay đổi như thế nào?”.</p><p> Để dễ hình dung, bạn hãy nghĩ đến tình huống sau đây. Giả sử bạn là một nhà nghiên cứu của tổ tư vấn Chính Phủ trong đợt dịch COVID-19 lần này, các câu hỏi bạn cần phải giải quyết như sau:</p><p> - “Nếu một người có triệu chứng sốt, ho khan, và mệt mỏi thì khả năng người đó nhiễm COVID-19 là bao nhiêu?”.</p><p> - “Nếu sử dụng loại thuốc X thì khả năng điều trị bệnh nhân nhiễm COVID thay đổi như thế nào?”.</p><p> - “Nếu chúng ta không áp dụng chính sách cách ly xã hội thì tổng số ca lây nhiễm COVID-19 sẽ thay đổi như thế nào?”.</p><p> Với câu hỏi ở tầng thứ nhất, trọng tâm là sự tương quan giữa các nhóm đối tượng được nghiên cứu. Có thể đưa ra dự báo dựa trên các mối liên hệ này và không nhất thiết phải lý giải chính xác về bản chất. Cụ thể, người ta sẽ quan tâm xem liệu một người bị mắc các triệu chứng trên sẽ có bao nhiêu % khả năng sẽ mắc COVID-19, và không cần quan tâm đến việc những triệu chứng ấy có liên quan gì đến căn bệnh đang xét đến hay không. </p><p> Sang đến hai câu sau, độ phức tạp của các vấn đề cần giải quyết đã tăng lên rất nhiều lần khi đề cập đến hai khái niệm nền tảng của lý thuyết suy diễn nhân quả, đó là (1) sự can thiệp và (2) các giả định phản thực.</p><p> Giải thích một cách đơn giản, sự can thiệp tức việc thực hiện một hành động cụ thể là nguyên nhân dẫn đến hệ quả tương ứng. Trong câu 2, sự can thiệp là việc “sử dụng loại thuốc X” còn hệ quả tương ứng là “sự thay đổi tình trạng sức khỏe của bệnh nhân nhiễm COVID-19”. </p><p> Ở tầng 3, giả định phản thực là khái niệm chỉ việc đặt ra các giả thuyết về những sự kiện có thể xảy ra nhưng đã không xảy ra trong thực tế. Trong câu 3, giả định phản thực là việc “không áp dụng chính sách cách ly xã hội” và hệ quả thực tế là “sự thay đổi tổng số ca lây nhiễm COVID-19”.</p><p> Nhìn chung, với nền tảng lý thuyết và các công cụ “suy diễn nhân quả”, cùng dữ liệu quan sát sẵn có, người ta có thể xác định được các mối quan hệ nhân quả giữa các biến số và định lượng mức độ ảnh hưởng của các biến nguyên nhân (gồm cả thực tế lẫn giả định) đến các biến hệ quả. Vậy thì…</p><p> 2.    Làm thế nào để giải quyết các bài toán suy diễn nhân quả?</p><p> Để giải quyết các bài toán ở tầng thứ nhất, chỉ cần thu thập đủ dữ liệu về các đối tượng cần nghiên cứu và phân tích sự tương quan của chúng. Trong kỉ nguyên dữ liệu lớn, việc khai thác thông tin từ dữ liệu quan sát và trả lời các câu hỏi nghiên cứu ở tầng một đã và đang được giải quyết rất tốt bởi các nhà khoa học máy tính và phân tích dữ liệu. Mặc dù vậy, họ sẽ phải tốn kha khá thời gian và công sức nghiên cứu nữa để có thể đưa “trí tuệ nhân tạo” đi từ việc tìm kiếm sự tương quan đến giải thích mối quan hệ nguyên nhân – hệ quả giữa dữ liệu đầu vào và đầu ra của mô hình [5].</p><p> (Giả sử điều này là cần thiết).</p><p> Bước sang tầng thứ 2, một phương pháp phổ biến được xem như tiêu chuẩn vàng (gold standard) trong việc xác định các mối quan hệ nhân quả là “Thử nghiệm ngẫu nhiên có đối chứng (Randomized Controlled Trial – RCT)” hay còn gọi là “thử nghiệm A/B”. Đây là một phương pháp thiết kế thí nghiệm đặc thù để so sánh sự khác biệt giữa hai hoặc nhiều nhóm đối tượng nghiên cứu khi áp dụng hoặc không áp dụng hành động can thiệp [6].</p><p> Tuy nhiên, RCT có nhiều điểm hạn chế như yêu cầu số lượng mẫu lớn, quy trình thiết kế và kiểm soát thí nghiệm nghiêm ngặt, chi phí cao và tốn nhiều thời gian thực hiện. Và không phải lúc nào phương pháp này cũng được áp dụng hoặc thậm chí không thể thực hiện được. Ví dụ khi nghiên cứu về ảnh hưởng của khói thuốc lá đối với trẻ em, các giới hạn đạo đức không cho phép chúng ta chia đám trẻ thành 2 nhóm và cho 1 trong 2 nhóm hít khói thuốc lá rồi so sánh đối chứng được.</p><p> Nhưng những câu hỏi đã đặt ra không thể không trả lời. Do đó, Judea Pearl đã phát triển một hướng tiếp cận mới gọi là Sơ đồ Nhân quả (Causal diagram). Phương pháp này hoàn toàn dựa vào các dữ liệu quan sát sẵn có, đặt ra các giả thuyết về mối quan hệ tương tác nhân quả giữa các biến, cho phép chúng ta dự đoán kết quả nghiên cứu sẽ thay đổi như thế nào khi có can thiệp xảy ra mà không cần trực tiếp thực hiện thí nghiệm so sánh [7].</p><p> Về mặt cấu trúc, một sơ đồ nhân quả đơn giản bao gồm các điểm (nodes) đại diện cho các biến nguyên nhân (X), hệ quả ( Y ), và các yếu tố ảnh hưởng (Z) đến nguyên nhân và/hoặc hệ quả, cùng các mũi tên biểu diễn giả thuyết quan hệ nhân quả giữa các biến. Một sơ đồ nhân quả đầy đủ kết hợp với lý thuyết xác suất có điều kiện có thể mô phỏng chính xác kết quả của các thí nghiệm can thiệp mà không cần trực tiếp thực hiện nó [8]. Điều này giúp một vài sự kiện không thể vẫn có thể hiện ra một cách tương đối rõ ràng thông qua các công thức toán học.</p><p> Đối với bài toán ở tầng cuối cùng, tồn tại một vấn đề lớn khác là chúng ta không thể quay ngược thời gian để thiết kế các thí nghiệm so sánh đối với những sự kiện đã xảy ra. Do đó, mô hình phương trình cấu trúc (Structural Equation Model) được xây dựng dựa trên sơ đồ nhân quả có thể mô phỏng các yếu tố giả định phản thực (thực hiện/không thực hiện can thiệp), trong đó mối quan hệ giữa các node trong sơ đồ nhân quả được xác định rõ ràng thông qua các phương trình tương ứng giữa các biến cố nguyên nhân và hệ quả [9].</p><p> (Với những bạn đọc không biết về XSTK, có thể đọc lại câu cuối ở đoạn phía trên nữa để hiểu đoạn vừa rồi).</p><p> Nhân tiện, khi nói về các yếu tố ảnh hưởng (Z), có hai yếu tố ảnh hưởng cần chú ý trong việc xây dựng các mô hình nhân quả, bao gồm confounder (X←Z→Y) và collider (X→Z←Y). </p><p> Trong đó, confounder là yếu tố ảnh hưởng tác động đến cả nguyên nhân lẫn hệ quả, nhưng lại khó xác định và thường xuyên bị bỏ sót, dẫn đến các kết luận suy diễn ngớ ngẩn hoặc sai lầm. Ví dụ như kết luận “( Y ) tỷ lệ trẻ em đuối nước tăng là do (X) doanh số bán kem tăng” trong bài kì trước, yếu tố ảnh hưởng bị bỏ sót là “(Z) kì nghỉ hè”.</p><p> Còn collider là một khái niệm khá... “lừa đảo”. Chẳng hạn, trong một vài sơ đồ nhân quả như: Dậy trễ → Đi làm trễ (collider) ← Kẹt xe, việc dậy trễ hoặc kẹt xe cũng là nguyên nhân ta đi làm trễ; nhưng chắc chắn dậy trễ không gây nên tình trạng kẹt xe và ngược lại. Bên cạnh đó, khi một biến collider đã được giải thích bằng một nguyên nhân, sẽ có rất ít khả năng cả hai nguyên nhân cùng xảy ra, dễ dẫn đến thiên vị (collider bias) [10].</p><p> Một ví dụ điển hình của collider bias là nghịch lý béo phì (obesity paradox). Cụ thể, khi nghiên cứu về ảnh hưởng của béo phì đến tỷ lệ tử vong so với các nguyên nhân khác, nếu mẫu khảo sát chỉ gồm những bệnh nhân mắc các bệnh mãn tính như bệnh tim mạch, béo phì lại cho thấy nó làm giảm tỷ lệ tử vong so với các yếu tố khác; nhưng trên thực tế, béo phì làm tăng tỷ lệ tử vong trong mẫu khảo sát lớn hơn (bao gồm các bệnh nhân có và không có bệnh tim mạch). Do bệnh tim mạch là collider giữa béo phì và các yếu tố khác, vì thế đã làm giảm đi ảnh hưởng của béo phì đối với tỷ lệ tử vong  [11]. </p><p> Nhìn chung, nền tảng của suy diễn nhân quả đều xoay quanh các giả thuyết về mối quan hệ nguyên nhân - kết quả và các yếu tố ảnh hưởng. Mặc dù chỉ mang tính giả định, chủ quan và không thể kiểm chứng (như các bài toán phản thực), nhưng việc có thể xác định chính xác nguyên nhân dẫn đến một tình huống hoặc kết quả cụ thể vẫn sẽ đem lại giá trị tham khảo nhất định, từ đó có thể đưa ra những quyết định hợp lý hơn ở các trường hợp tương tự xảy ra trong tương lai. </p><p> (Ít nhất theo lý thuyết là thế!)</p><p> Nhưng không chỉ bản thân việc suy diễn nhân quả khá phức tạp và cần cẩn trọng, một điều quan trọng nữa cần ghi nhớ là các suy diễn thống kê chỉ có ý nghĩa (hoặc có độ tin cậy nhất định) trong một số điều kiện giả thuyết cho trước (background assumptions). Vượt ra khỏi những giả định này, các kết luận suy diễn thống kê được đưa ra đều vô nghĩa và không còn đáng tin cậy.</p><p> Chẳng hạn như khi tôi bảo rằng nếu bài viết này (bài viết đầu tiên của tôi ở Monster Box) được trên 1000 likes, vậy đây là một bài viết có giá trị với nhiều người. Nhưng điều đó chỉ đúng khi giả định rằng toàn bộ những người nhấn like đều đọc và hiểu hết bài viết.</p><p> Nếu giả định này sai…<br> #MonsterBox<br> ____________</p><p> CAUSAL INFERENCE - THE HIGHEST LEVEL OF STATISTICAL INFERENCE?</p><p> Statistical probability, the “wondrous” scientific instrument, has so far been the gizmo on which science (both natural and social), especially such innovative, 4.0 fields as AI, Big Data and Machine Learning fervently thrive. That said, dismally enough, every cutting edge invention’s “thaumaturgy”, given the gnarled human use, may end up neutralized or worse, distorted - which is self-evident in such ubiquitous “spells” as statistics and probability.</p><p> Albeit de facto wondrous, statistics and probability’s applications still are woefully convoluted, let alone their every tangible constraint - thus, seldom serve as a common base on which humans could leap to general conclusions. Within the context of our recent statistics-probability article, we, in this manner, did put accent on the perplexity of statistical predictions or any conclusions drawn from which - since rarely could humans identify the every variable that makes up the final results, their inter-variable relationships, nor the degrees to which they affect the end-products. </p><p> One critical “variable” in which, in turn, is the so-called "inter-variable relationships".</p><p> In statistics and probability, in scrutiny of two variables, scientists often turn to correlation to examine the in-between relationship. For example, when looking at the two sets of data: (1) “the Monster Box page’s likes” and (2) “Vietnam's average GDP”, should they engender analogous growth graphs (to come up with these seemingly straightforward figures, however, is woefully mathematically arduous), the very conclusion we thereby leap to is that these two variables are correlated.</p><p> Nevertheless, however kindred the two variables may be, rarely does it imply that either of which must inflict some impacts on the other. Simply put, that the Monster Box page soars in alignment with Vietnam's GDP may not mean that the company has somehow catalyzed the domestic economic growth.</p><p> After all, statisticians must have every reason to come up with a classic warning alongside: "Correlation does not imply Causation" [1]. So, ...</p><p> 1. What is Causal Inference?</p><p> Whenever an event, process, or state acts as a precursor to the creation of another event, process, state - new entities - our presumption is that there has been causation. In other words, causality can be interpreted no less straightforwardly: one causes the other.</p><p> In statistics and probability, "causal inference" denotes the very process to ferret out conclusions that, given every necessary condition, evidence the existence of causal, inter-variable relationships [2]. Studies on "causal inference" fervently flourished since as early as the 1980s, thereupon shaping every such science field as philosophy, education, statistics, computer science, health science, epidemiology, public policy and economics.</p><p> Still, it was not until 2000, when Judea Pearl introduced his masterpiece "Causality: Models, Reasoning, and Inference", that the theoretical foundation and mathematical mechanisms to engender "causal inference" was consolidated and completed [3].</p><p> In the aforementioned post, we did conjecture the utility of statistical data in “drawing the relationship between variables, thereby predicting the occurrence likelihood of a particular other - by observing which”. Albeit de facto sounding, this application is solely the lowest level in Judea Pearl’s three-step “causal inference” hierarchy. To put into perspective, Pearl purported the studies of "causal inference" must answer the three types of questions corresponding to three human perception levels, from simple to complex, by which he coined "the Ladder of Causation [4]. Its “steps” are as follows:</p><p> - Association: "If X is observed, how shall Y change?".</p><p> - Intervention: "If X is accomplished, how shall Y change?".</p><p> - Counterfactuals: "If X has already been carried out, how should Y have changed?".</p><p> To better visualize which, let us scrutinize a scenario as such: assume you are a researcher in the government consultant department, given this COVID-19 pandemic, the questions with which you must grapple are as follows:</p><p> - "If a person has developed symptoms of fever, dry cough, and fatigue, how likely is he infected?"</p><p> - "Should the X drug be applied to the treatment procedure, how shall it change?"</p><p> - "Unless we implement strict social distancing, how shall the total infection cases change?"</p><p> In the first stage, the focus is channeled on purely the correlations between the groups of subjects. Without any core explanations, researchers, nonetheless, may come up with predictions of which. In all likelihood, they shall zero in how an individual with such symptoms is prima facie infected, irregardless of the actual correlation between which and the illness.</p><p> Moving up onto the next two stages, however, the problems’ complexity - referring to the two fundamental concepts of causal inference: (1) intervention and (2) counterfactuals - exponentially escalates.</p><p> Simply put, intervention implies the execution of some particular actions has engendered the respective consequences. In the second stage, for example, the intervention - the "application of drug X" - breeds the corresponding consequence of "changes in the treatment output".</p><p> In the third, counterfactuals denote the could-have-occured-but-did-de-facto-not hypothesis, in this case, the "social distancing policy" and the consequence of "changes in the total number of infections".</p><p> In general, given the theoretical background, these "causal inference" tools, alongside available observation data, scientists can thereby determine the causal, inter-variable relationships between the variables, and evaluate the impacts of which (both actual and hypothetical) on consequential variables. Then,...</p><p> 2. ...How to address causal inference?</p><p> To solve the first-stage problem, the necessary condition is sufficient data on subjects and analyses of their correlations. In the big data epoch, the information refinement from observational data and handling of the first-stage questions, to computer scientists and data analysts, seem any less no-brainers. Nevertheless, to get "artificial intelligence" to reason out the causal relationships - between input and output data - from merely ferreting out the correlations would be woefully arduous [5].</p><p> (In case this is indeed necessary).</p><p> Moving on to the second stage, the popular so-called “gold standard” in identifying inter-variable relationships is the "Randomized Controlled Trial (RCT)", or the conventional "A/B testing". This is a specialized experimental design method to contrast the differences between two or more subject groups, either with or without intervention [6].</p><p> Still, RCT holds every such constraint as the prerequisite of myriads of samples, stringent design-and-test procedures, high costs, along with the time-consuming implementation of which. Worse still, the method is de facto rarely applicable. For example, given a study on the tobacco smoke’s impacts on children, every social, moral norm seldom allows us to divide children into two groups, getting one exposed to such hazardous aerosol to eventually engender some comparisons.</p><p> That said, never could scientists simply pass over what they themselves have propelled forward. In this manner, Judea Pearl, in his book, also devised another new approach - the Causal diagram. This method relies mostly on available observational data, thereby making hypotheses about causal relationships between variables, predicting how the end-products shall shape, given the interventions, without any direct comparative experiments [7].</p><p> To put its structure into perspective, a simple causal diagram consists of nodes that represent cause variables (X), consequences ( Y ), and side factors (Z) that distort the former, with arrows demonstrating the hypothesized inter-variable causality. A such complete causal diagram, alongside the theory of conditional probability, can thus accurately simulate the results of intervention experiments [8], thereafter revealing some no-solution events through mathematical formulas.</p><p> To the third, however, another popping-by, crippling problem is that seldom could we go back in time to design comparative experiments for de-facto-happened events. Thus, researchers have come up with the so-called Structural Equation Model, the groundwork of which is a causal diagram capable of simulating the counterfactual factors (with/without intervention), in which the node correlation within the diagram is clearly demonstrated in the equations corresponding to cause and consequence variables [9].</p><p> (To those lacking statistics and probability knowledge, please turn to the previous paragraph to somehow interpret this).</p><p> While on the subject - of the influential factors (Z) - the two types of effects to heed in the construction of causal diagrams include the confounder (X ← Z → Y), and collider (X → Z ← Y).</p><p> In particular, the confounder is what drives both causes and consequences, but is difficult to identify, thus often overpassed, thereby breeding drearily dull, or erroneous inference. For example, our such conclusion (in the previous post) was (X) “the surge in the number of child drowning is due to ( Y ) an increase in ice cream sales”, wherein the omitted factor was “(Z) summer vacation”.</p><p> Collider, on the other hand, is much akin to a "scam". To demonstrate, in such a causal diagram as: Wake up late → Late to work ← Traffic jams, whilst “waking up late” or “traffic jams” serves as every reason to champion one’s late to work; neither of which ever engenders traffic jams and vice versa. Still, a collider variable, once explained by a cause, would, in all likelihood, stave off the other, leading all the way to collider bias [10].</p><p> A sounding example of which is the obesity paradox. Simply put, in a study of obesity’s effects, as compared to other causes, on mortality: if the sample population is purely patients with such chronic diseases as cardiovascular, the former even evidences itself as a “helping hand” that dwindles mortality compared to other factors; even though obesity is de facto conducive to which in larger samples (involving patients with/without cardiovascular diseases). As the collider between obesity and other factors, cardiovascular diseases, in this case, somehow alleviate every obesity’s actual impact on mortality [11].</p><p> In general, the very foundation of causal inference revolves around hypotheses on cause-consequence relationships, along with every side variable. Albeit merely hypothetical, subjective, thus unverifiable (akin to counterfactuals), the identification of the exact causes of a particular situation, or its possible outcomes still offer some referencing values, thereupon catalyzing more reasonable decisions in similar future cases.</p><p> (by the book, at least!)</p><p> Not only is the causal inference itself woefully perplexing, it seems critical that every statistical inference is only valid (reliable) under certain pre-existing hypothetical conditions. Beyond which, statistical inference conclusions should be neither.</p><p> For example, to attain as much as 1000 likes, this post (my very debut) must be either sounding or offer some intelligible values to that many people. Which, nonetheless, only comes true should they have read the article inside-out and understand it.</p><p> Otherwise,...<br> <a class="_58cn" href="/hashtag/monsterbox?__eep__=6&amp;source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARAKu9ohWzVZkA3l_SdhgcEBa-nA0lBs_V3C57067r_CoYlzlSMZrQQwLkQR7eb-J7x7qdT5FOX8kBa4g34ouH0sHcmqE06L25PHzQyDwSVUCFGOD1wLVndeoZLv4WQV3FQEisz9cwyP5TFar_1QN5qkwxjfV1InwHXKIGrfnCvvb01cUoYSjih30tjPgS2BPCg1YTnBRCgi2SXVzlFntt_s51YB4bd8qSl0ZX0s5ZKX8X-q656lowpUphTY41PRNRCiP7vRws6W3J2mwublyANICYvzuAyL5GM26uh8Pi8A_GY-vNefQBQ&amp;__tn__=%2ANK-R" data-ft="{&quot;type&quot;:104,&quot;tn&quot;:&quot;*N&quot;}"><span class="_5afx"><span aria-label="hashtag" class="_58cl _5afz">#</span><span class="_58cm">MonsterBox</span></span></a></p><p> - Artist: Sam.<br> - Trans: Heinous.</p>