<p>[English Below]</p><p> XÁC SUẤT THỐNG KÊ VÀ LỜI NGUYỀN DỄ BỊ LỢI DỤNG CỦA NHỮNG THỨ ĐÁNG TIN CẬY.</p><p> Khoa học là thước đo đáng tin cậy nhất ở thời điểm hiện tại. Vì vậy, có thể dễ dàng nhận thấy trong thời gian gần đây, nhiều lĩnh vực có xu thế tự nhận mình có nền tảng “khoa học” để trở nên đáng tin hơn với đại chúng.</p><p> Nếu như việc các nhãn hàng dùng những chiến dịch marketing để chứng minh sản phẩm của mình “được các nhà khoa học khuyên dùng”, “được khoa học chứng minh tốt cho sức khỏe”... vẫn còn tương đối dễ hiểu (dù thực chất chúng không “khoa học” đến thế), thì việc những lĩnh vực vốn trái ngược với khoa học cũng tự nhận mình “khoa học” khá buồn cười.</p><p> Chúng ta thường xuyên nhìn thấy một vài tôn giáo, hay những bộ môn huyền học, mê tín dị đoan như bói toán, tướng số, chiêm tinh, tarot, sinh trắc vân tay… thỉnh thoảng cũng tự khẳng định tính “khoa học” của mình. Rất có thể đó chỉ là sự biến tướng của những người hành nghề, còn lý thuyết nền tảng truyền thống không có sự thay đổi. Tuy vậy, không thể phủ nhận rằng xu thế này đang dần biến chúng thành các bộ môn ngụy khoa học và còn mất nhiều uy tín hơn cả khi chúng trung thành đi theo nền tảng lý lẽ truyền thống.</p><p> Trong xu thế này, xác suất thống kê (XSTK) cũng là một lĩnh vực khoa học thường xuyên bị lợi dụng bởi nhiều bên khác nhau như các bộ môn mê tín dị đoan, báo chí giật tít, các chính trị gia hay thậm chí những nhà khoa học đang cần chạy số lượng nghiên cứu. </p><p> XSTK đặc biệt dễ lợi dụng, vì thậm chí ngay cả khi các nhà nghiên cứu cẩn thận và nghiêm túc, họ vẫn có thể vô tình mắc phải những lỗi lầm khiến thu được kết quả sai lệch, vô giá trị hay thậm chí có hại.</p><p> 1. Một vài kiểu lợi dụng phổ biến.</p><p> a) Cố tình loại bỏ các quan sát không có lợi [1].</p><p> Trong quá trình chạy mô hình hoặc khảo sát, người thực hiện có toàn quyền quyết định loại bỏ những kết quả không có lợi so với định hướng ban đầu của mình và làm lại hoặc chỉ chọn dùng số đúng ý. Vấn đề này cũng xảy ra trong chuyện công bố nghiên cứu, khi các tổ chức, cá nhân chủ động chọn công bố những nghiên cứu có lợi cho mục đích ban đầu của mình.</p><p> Chẳng hạn, các công ty thuốc lá chọn công bố những nghiên cứu cho thấy hút thuốc không liên quan đến ung thư, trong khi những tổ chức phản đối thuốc lá lại chọn công bố những nghiên cứu theo chiều hướng tuyên truyền về tác hại của thuốc lá. </p><p> Xu hướng này dường như đang tồn tại như một vấn nạn ở nhiều cấp độ, từ nhà nghiên cứu, nhà xuất bản cho đến các phương tiện truyền thông đại chúng. Trong lĩnh vực xuất bản nghiên cứu, người ta gọi đây là “thiên kiến xuất bản” (publication bias) và lượng rất lớn những nghiên cứu không có kết luận (đôi khi bao gồm cả những nghiên cứu có kết luận tiêu cực) không được công bố. </p><p> Ví dụ, giả sử có 50 nghiên cứu về sữa X của hãng nào đó được thực hiện, đôi khi công chúng sẽ chỉ được nghe về 1 nghiên cứu có kết luận tích cực như “uống sữa X tốt cho tăng trưởng chiều cao”, trong khi 48 nghiên cứu còn lại đưa ra kết luận trung tính và 1 kết luận tiêu cực.</p><p> Trong cuộc sống thường ngày, việc cố tình không công bố kết quả bất lợi cũng diễn ra nhan nhản khiến chúng ta hiểu sai lệch về thực tế cuộc sống diễn ra. </p><p> Chẳng hạn, một người mỗi ngày gửi 100 con lô cho 100 người bất kỳ, sau đó có thể chọn chụp màn hình inbox người trúng để khoe cùng lúc giấu đi hàng chục người khác đang chửi bới vì thua cuộc. Những người hành nghề bói toán cũng dùng cách tương tự. Sách self-help cũng tập trung kể ra những tấm gương thành công và bỏ qua số lượng lớn thất bại. Và gần gũi hơn, mọi người dường như cũng thích khoe những khoảnh khắc thú vị hiếm hoi trong cuộc sống của họ, cùng lúc giấu đi phần lớn thời gian nhàm chán tẻ nhạt.</p><p> Tuy nhiên, thiên kiến xuất bản còn nguy hiểm ở chỗ luôn có một tỉ lệ nhất định tồn tại những ngoại lệ. Giả sử, khi đưa ra tuyên bố “hút thuốc lá gây ung thư” với tỷ lệ tin cậy (confidence level) là 99%. Vậy, sau khi thực hiện 1000 thí nghiệm, sẽ có khoảng 990 thí nghiệm đồng ý với giả thuyết trên và LUÔN tồn tại 10 nghiên cứu cho ra kết quả ngược lại hoặc không có kết luận. Giả sử trong đó có 5 thí nghiệm đưa ra kết luận rằng “hút thuốc lá không liên quan đến ung thư”. Vậy, một số công ty thuốc lá và các tờ báo có thể nhặt về để truyền thông rằng: “Nhiều nghiên cứu cho thấy thuốc lá không gây ung thư”.</p><p> Ngay cả khi chỉ dừng lại ở một kết quả “có ý nghĩa về mặt thống kê” (chưa chắc đã có ý nghĩa trên thực tế), đã luôn tồn tại số lượng nhất định những thí nghiệm thiểu số đưa ra kết luận ngược lại với tuyên bố ban đầu. Nhiều người nhắm vào đó, thay vì bức tranh toàn cảnh, để vẽ lên một hiện thực không có thật.</p><p> b) Nhân quả ảo [2].</p><p> Với hai biến A và B tương quan với nhau, có thể suy diễn 6 loại mối quan hệ giữa chúng:</p><p> - A gây ra B</p><p> - B gây ra A</p><p> - Cả A và B đều một phần là nguyên nhân của nhau.</p><p> - A và B đều cùng bị gây ra bởi C.</p><p> - B bị gây ra bởi C, trong khi C tương quan với A.</p><p> - Chúng tương quan một cách hoàn toàn ngẫu nhiên.</p><p> Mối quan hệ thứ 6 là thứ dễ gây hiểu nhầm. Vì mặc dù trong thống kê, các chuyên gia biết rằng “tương quan thì không bao hàm nhân quả” và sự tương đồng của đồ thị đôi lúc chẳng chứng minh điều gì, nhưng với trực giác của người bình thường, chúng ta vẫn thường lấp đầy những vùng xám không rõ ràng bằng lý lẽ cảm tính để mọi thứ trở nên “có nghĩa” và “drama” hơn.</p><p> Chúng ta đã nghe đi nghe lại nhiều lần về bài toán kem và trẻ chết đuối, khi thống kê trong nhiều năm đều cho thấy mỗi khi doanh số bán kem tăng, số trẻ chết đuối cũng tăng. Về sau người ta nhận thấy rằng nguyên nhân chính khiến cả hai chỉ số này đều tăng đó là kỳ nghỉ hè, chứ không phải việc ăn kem khiến trẻ em bơi kém đi. Nhưng ngay cả khi chưa nghe đến nguyên nhân là mùa hè, ắt hẳn chúng ta cũng không nghĩ rằng ăn kem có liên quan đến chết đuối, vì điều này khá phản trực giác.</p><p> Nhưng nếu như những biến ngẫu nhiên này được thay bằng các biến phù hợp với trực giác hơn thì sao? Ví dụ như “chất hóa học A” và “bệnh ung thư”, hay “số trẻ được tiêm vaccine” và “số trẻ em bị tự kỷ”?</p><p> Việc đưa ra 2 đồ thị tương quan (nhưng không nhân quả) về những chuyện nhạy cảm như “dữ liệu cho thấy càng nhiều trẻ em được tiêm vaccine, càng nhiều trẻ bị tự kỷ” rất dễ tạo ra hiện tượng “lên đồng tập thể” trong dư luận, dù rất có thể biến cố chính dẫn đến cả hai xu hướng trên là tỷ suất sinh tăng.</p><p> Thực tế chuyện này diễn ra tương đối phổ biến, ví dụ các cáo buộc liên quan đến việc “sống dưới đường dây cao thế khiến tăng khả năng mắc bệnh ung thư” cũng đã gây rất nhiều tranh cãi và nhiều nhà khoa học cho rằng đây chỉ là tương quan chứ không phải nhân quả [3]. Nhiều ý kiến cho rằng không phải đường dây cao thế, chính gia cảnh của những gia đình phải sống dưới đường dây cao thế mới là nguyên nhân chính cho tỷ lệ mắc ung thư cao bất thường. Vì những khu vực có đường điện cao thế thường nằm ở nông thôn, khu vực hẻo lánh, nên những gia đình sống ở đây cũng thường có điều kiện sống không đảm bảo, chế độ dinh dưỡng kém và thiếu thốn nhiều phúc lợi xã hội, do vậy tỷ lệ mắc bệnh ung thư cũng cao hơn so với người dân ở các khu vực khác [4].</p><p> Với những vấn đề phức tạp như bệnh ung thư thường có nhiều tác động phức tạp, vì thế không thể dễ dàng đưa ra kết luận cho một nguyên nhân cụ thể nào đó. Nhiều vấn đề khác cũng tương tự. Vì thế, các để xem liệu “A có gây ra B” hay không, người ta phải thiết kế hai thí nghiệm mà B và B’ có nhiều điểm tương đồng nhất có thể, đồng thời B chịu ảnh hưởng bởi A (nhóm thí nghiệm) trong khi B’ thì không (nhóm đối chứng).</p><p> Chẳng hạn, ở câu chuyện về đường điện cao thế, sẽ cần có hai nhóm người có điều kiện sống tương đồng, trong đó một nhóm sống dưới đường điện, một nhóm không để đối chứng. Tuy vậy, những thí nghiệm này rất khó thực hiện trong thực tế, vì thường tốn kém, thiếu thực tế, phi đạo đức và dễ gây tranh cãi. </p><p> Do đó, một số vấn đề ai cũng thấy, cũng muốn giải quyết, thậm chí có hướng giải quyết, nhưng mãi không thể giải quyết được vì nhiều giới hạn. Cuộc sống vốn không lý tưởng (và môi trường khoa học cũng vậy), nên luôn tồn tại một vài vùng xám bị khai thác và lợi dụng.</p><p> c) Hiểu nhầm ý nghĩa thống kê là ý nghĩa thực tiễn [5].</p><p> Phía trên tôi có mở ngoặc một chỗ để note rằng “ngay cả khi chỉ dừng lại ở một kết quả “có ý nghĩa về mặt thống kê” để mọi người hiểu rằng ý nghĩa thống kê không nhất thiết phải tạo ra ý nghĩa trên thực tế. Chẳng hạn, khi một ai đó đưa ra tuyên bố rằng “ăn nhiều thì sẽ no” và sau hàng loạt nghiên cứu đạt chuẩn, kết quả thống kê cho thấy phần lớn nghiên cứu chỉ ra kết quả đúng như tuyến bố ban đầu, vậy ta nói nó “có ý nghĩa về mặt thống kê”. </p><p> Tất nhiên những kết quả có ý nghĩa về mặt thống kê có thể có ý nghĩa trên thực tế, tuy vậy điều này không phải luôn xảy ra. Với lượng lớn nghiên cứu, thống kê khoa học được thực hiện mỗi ngày, phần lớn trong số đó tập trung giải quyết một vấn đề trong bối cảnh rất nhỏ, các nhà nghiên cứu cũng đặt mục tiêu đáp ứng “ý nghĩa về mặt thống kê” trước thay vì mục tiêu thay đổi thế giới như chúng ta vẫn nghĩ. Đôi lúc kết quả đưa ra chỉ là thay đổi rất nhỏ. Do vậy, những kết luận có ý nghĩa về mặt thống kê này đôi khi trở nên vô dụng và sai lệch khi đặt ra khỏi bối cảnh của nghiên cứu/khảo sát.</p><p> Ví dụ, khi thiết kế một thí nghiệm về việc “kem đánh răng giúp trắng răng”, các nhà nghiên cứu chỉ cần đảm bảo rằng có sự thay đổi sắc độ ở những chiếc răng được thử nghiệm với kem đánh răng, bất kể rằng chỉ có thể nhận ra điều đó dưới các dụng cụ đo thay vì mắt thường. Tương tự, khi làm một nghiên cứu về “thuốc giúp chữa bệnh hói”, loại thuốc ấy chỉ cần đảm bảo rằng vùng da bị hói có thể mọc lông tơ để có thể được công nhận là “có ý nghĩa về mặt thống kê”. Cả hai sự khác biệt trên dường như vô dụng trong ứng dụng thực tế.</p><p> Vì vậy, ý nghĩa thống kê thường được dùng để biểu thị cho xác suất, trong khi ý nghĩa thực tiễn mới là thứ nói lên độ hữu dụng của nghiên cứu/thống kê đó. Nhưng truyền thông và các nhãn hàng vẫn thường dùng kết luận “có ý nghĩa thống kê” để công bố mà không nói gì thêm, khiến đại chúng nhầm lẫn về ý nghĩa thực sự của chúng.</p><p> d) Những kiểu ngụy biện và lợi dụng khác.</p><p> “Hỏi gài” (loaded questions) [6] là việc người thống kê cố tình đưa ra các câu hỏi không trung lập từ đầu để định hướng câu trả lời của người tham gia khảo sát. Chẳng hạn khi khảo sát về độ yêu thích Monster Box, có thể đặt hai câu khác nhau cho cùng một nội dung muốn hỏi: </p><p> - Bạn có ủng hộ việc Monster Box bài trừ mê tín dị đoan và nâng cao nhận thức của mọi người về khoa học không?</p><p> Và:</p><p> - Bạn có ủng hộ việc Monster Box đụng chạm vô cớ, liên tục gây sự với những lĩnh vực khác ngoài khoa học không?</p><p> Ngoài ra, “tổng quát hóa quá mức” (overgeneralization) [7] cũng là một cách thường xuyên được sử dụng để đưa ra kết luận to dựa trên một mẫu khảo sát không có tính đại diện. Chẳng hạn, chúng ta có thể kết luận rằng “chó là loài động vật 4 chân” sau khi đã nhìn thấy đủ nhiều giống chó trên thế giới. Tuy vậy, không thể vì nhìn thấy cả bầy samoyed rồi có thể đi đến kết luận rằng tất cả chó đều có màu trắng và lông xù.</p><p> Điều này tưởng chừng như hiển nhiên, nhưng xảy ra rất thường xuyên với những khảo sát phức tạp và tinh vi. Chẳng hạn, khảo sát người sống ở thành phố tất nhiên không thể đại diện cho những người dưới nông thôn, khảo sát người lớn không đại diện được cho trẻ em… nhưng đôi lúc mẫu khảo sát được giữ kín, và người ta dễ dàng bị nhầm lẫn rằng những kết quả thống kê này đủ sức để đại diện ở mức tổng quát.</p><p> 2. Thống kê không quá thần kỳ, nhưng kỳ diệu.</p><p> Chúng ta thường lấp đầy những khoảng trống ở những lĩnh vực mình không biết thông qua việc “tưởng rằng” như thế này, “tưởng rằng” như thế kia. Chẳng hạn, tôi có gặp nhiều người lý tưởng hóa các công cụ khoa học đến mức cho rằng nó có thể làm tất cả mọi thứ nếu muốn và nhất định phải cho ra kết quả chính xác. Vì vậy, khi kết quả đưa ra sau đó lộ ra là sai lầm, vậy nghĩa là khoa học chưa đáng tin.</p><p> Thực ra, khoa học và những hệ thống công cụ phía trong nó được phát triển dựa trên việc biết rằng chúng ta không thể làm tất cả mọi thứ mình muốn ngay lập tức. Đây là hệ thống có mức độ chuẩn xác đáng tin cậy khi nhìn từ góc rộng, nhưng phải cực kỳ cẩn thận phóng chiếu cụ thể vào từng nghiên cứu, thí nghiệm, khảo sát. Hệ thống khoa học đáng tin cậy không phải ở chỗ nó đảm bảo rằng mọi nghiên cứu đều chính xác, mà đáng tin cậy ở việc nó đảm bảo rằng ngay cả khi có rất nhiều nghiên cứu láo, chúng vẫn không thể qua mặt được bộ lọc lớn.</p><p> Chẳng hạn, trong XSTK, người ta biết rằng không thể nào khảo sát đúng và đủ ý kiến của 100 triệu người. Tuy vậy, họ có phương pháp để sao cho ý kiến của khoảng 5000 người có thể đại diện cho 100 triệu người kia. Và để làm được điều đó, mọi thứ cần được thực hiện theo đúng quy chuẩn được định ra bởi hệ thống XSTK lâu đời. Vậy, bất kỳ nhà nghiên cứu nào thực hiện đúng quy trình của XSTK, nghiên cứu của họ sẽ được gắn một mác vô hình dạng “kết quả có ý nghĩa thống kê và được đảm bảo bởi hệ thống XSTK toàn cầu”.</p><p> Và chỉ thế thôi.</p><p> Việc tuân theo những hệ quy chuẩn này không nhất thiết dẫn đến chân lý ngay lập tức, nhưng nó là một bước quan trọng trong hệ thống học thuật khoa học chuyên nghiệp bậc nhất hiện nay. Và cái hay của nó nằm ở việc dù không cam đoan bất kỳ điều gì là chân lý (chỉ tập trung vào luật chơi của riêng mình), nhưng lại tạo ra được hàng loạt sản phẩm thực tế đã đang và sẽ tiếp tục thay đổi thế giới. Toàn bộ các ngành khoa học trong cách mạng công nghệ 4.0 đều có nền tảng là XSTK, chẳng hạn như thuật toán giúp bạn nhìn thấy bài viết này.</p><p> Tuy vậy, hãy biết rằng XSTK là một quy trình phức tạp và mọi kết luận của nó phải đi cùng những thứ đã tạo ra kết luận ấy. Chẳng hạn, kết luận phải đi từ số mẫu thu thập được, dựa trên tuyên bố giả định ban đầu, trong một môi trường được quy định điều kiện rõ ràng, nằm trong giới hạn sai số cho trước, và các mối quan hệ nếu có phải được xác định rõ.</p><p> Vì thế, trong phần lớn thời gian, các mô hình thống kê thiếu đi tính thực tế (những thứ thực sự có thể xảy ra). Như một tay poker chuyên nghiệp có thể tính toán rất tốt xác suất thắng cuộc của mình dựa trên các lá bài và tiền cược, nhưng quên mất rằng có thể bị đối thủ chơi bẩn hay gian lận - những điều thực sự thường xuyên xảy ra trong thực tế. Đây cũng là lý do khiến đôi lúc các mô hình không dự đoán được thực tế, tạo ra thiên nga đen, do thực tế quá phức tạp với nhiều biến số không thể ngờ so với các mô hình.</p><p> Nghe có vẻ không kỳ diệu lắm? Đúng, nhưng thế giới bạn đang sống được xây dựng dựa trên những thứ phức tạp, khô khan và máy móc kiểu vậy.</p><p> Còn những thứ nghe kỳ diệu, tàu nhanh... thống kê cho thấy đều là lừa đảo hết cả lượt.<br> #MonsterBox<br> ___________</p><p> [English Below]</p><p> STATISTICAL PROBABILITY AND THE VULNERABILITY CURE OF MUST-HAVE-BEEN RELIABLE THINGS</p><p> To date, atop which is science. Given that, every emerging field can label itself with the so-called "scientific basis” to earn some catchpenny credibility, further sucking the public in.</p><p> Whilst marketing campaigns have all too often bragged of their recommended-by-scientists, scientifically-proven-healthy products, albeit de facto not that "scientific", that every anti-science field has since disguised itself as "science-based" must sound no less derisory.</p><p> To a certain extent, the modern world must have witnessed some religions, or such xuanxues as divination, physiognomy, astrology, tarot, fingerprint biometrics stickering themselves "scientifically sounding". Given that such movements might have been the practitioners disguising their “science”, and that the primitive foundations of which are yet changed, it seems inescapable that such a catchpenny, deceptive trick has denuded, turning them into pseudoscience, thus divesting them of every original credibility (were they to perpetuate conventional practices without the so-called “science foundation”).</p><p> Statistical probability, in this manner, has been serving as the ultimate scientific tool to fuel superstitions, tabloid media, politicians or even quantity-based researchers.</p><p> Statistical probability is thus so woefully vulnerable (to exploitation) that even researchers, with meticulosity and earnestness, unconsciously could fall for mistakes that yield erroneous, valueless, or even seemingly “malicious” results.</p><p> 1. Common exploitation techniques</p><p> a) Deliberate rejections of unfavorable observations [1]</p><p> Adopting this technique, accordingly, the implementer discards every unfavorable result from the original orientation, thereafter re-conducting pilot-run/survey, or reporting solely the benign findings. This problem, thus, has predominated research publications - since organizations and individuals only publish beneficial figures to their original purposes.</p><p> Tobacco companies, for example, often report studies “evidencing” that smoking rarely breeds cancer, whilst the counterparts - anti-tobacco groups propagate its every adverse impact instead.</p><p> This, however, seems to engender a latent, multi-level problem within the media, publishers, and even researchers. In the research ​​publication field, this is referred to as "publication bias", implying that every other inconclusive study (or those with unfavorable conclusions) has been deeply buried alongside.</p><p> For example, given 50 previous studies on milk X, the only finding presumably spreaded publicly is, as a rule, "milk X is conducive to height growth", though the remaining 48 studies yield neutral results and one even proves its harmful impacts.</p><p> In everyday life, the ubiquitous, cunning intentions of tucking away adverse results have also distorted our perception on the so-called reality.</p><p> Oftentimes, a person “consulting” different daily lottery results to 100 others can screenshot the winners, blowing his horn about his all-powerful “predictions” whilst lying low the losing, frustrating majority. So do fortune-tellers. Self-helps, in a like manner, also channel the public attention to the “achievers”, leaving aside the predominant population of “underachievers”. Even we, the ordinary, are tilted towards exulting the seldom interesting daily moments, upon having stowed away the dull others.</p><p> However, what makes the most hazards out of the publication bias is the certain proportion of exceptions. Supposedly, the “smoking causes cancer” statement rolls in with a confidence level of 99%. After a thousand studies, there, thus, should be as much as 990 studies favoring the hypothesis, while the rest - ten studies engender opposite or inconclusive results. Should half of which conclude that "smoking is not related to cancer", this very conclusion would be distorted as: "MANY studies show that tobacco does not cause cancer".</p><p> So, even though certain findings are merely "statistically sounding" (which denotes its unidentified practicality), there are inherently experiments, albeit in minority, that counter-argue the original statement. Many people have aimed at which, instead of the overall picture, to make up a fallacious reality.</p><p> b) Counterfeit causality [2]</p><p> Given two correlated variables A and B, it is possible to deduce 6 types of in-between relationship:</p><p> - A causes B.</p><p> - B causes A.</p><p> - Either somehow engenders the other.</p><p> - A and B are the consequences of C.</p><p> - C causes B, and the former is correlated with A.</p><p> - They correlate haphazardly.</p><p> This haphazard correlation is, nonetheless, bewildering. Whilst statistics experts know all too well that "correlation does imply neither cause nor effect" and that the diagram similarities may prove nothing, the ordinary, given their human intuition, often fill in obscure blanks with every emotional reason to earn things some "meanings" and themselves some "dramas".</p><p> Oftentimes, we are all too heard of about the ice cream-children drowning paradox - as statistics evidence that ice cream sales increase proportionally with the number of drowning children. Seldom did the former hobble the young’s swimming skills - it was not until much later did scientists found that the “catalyst” of both was the summer vacation. We, nevertheless, would ever puzzle over such correlation, irregardless of this very cause.</p><p> That said, what if these seemingly hazard variables are replaced by “more intuitive” - for example, "chemical A" and "cancer", or "number of vaccinated children" and "those with autism"?</p><p> The comparisons of two correlation (but not causal) diagrams of such sensitive things as "the more children are vaccinated, the more they abear autism", in all likelihood, spark every public controversy, even though the main cause of both might have been the upsurge fertility rate.</p><p> In fact, this is woefully common. The allegations that "lives under high-voltage lines are prone to cancer" has fuelled fierce controversies, howbeit many scientists have claimed that this is by all means a correlation - instead of a causal relationship [3]. They, accordingly, purported that it is the poor living conditions, not the electricity, under high-voltage lines that has bred a such abnormally high cancer rate. These areas are often rural and remote, thus families thereby often have unsecured living conditions, poor nutrition and lack of social welfare, thence bearing with higher cancer incidence than those in other areas [4].</p><p> Since such convoluted problems as cancer often encapsulate heaps of latent factors, it seems impossible to leap to conclusions from some particular causes. Neither do others. </p><p> To prove whether "A causes B", one must design two experiments wherein B and B' are as similar as possible, yet while B is indeed influenced by A (experimental group), B’ is not (control group).</p><p> To put the aforementioned high-voltage line paradox into perspective, [to prove either of the conclusions], there require two subject groups in kindred living conditions, one group under the power line, while the other is not. Nevertheless, a such experiment is practically arduous - it must be extravagant, unprofitable, unethical and no less controversial.</p><p> In this manner, even when some problems are de facto self-evident, aching, yet handleable, seldom are they handled. For life is no more ideal (so is science), the subsistence of obscure, vulnerable-to-exploitation areas, thus, is deemed inescapable.</p><p> c) Mistaking statistical significance for practical ones [5]</p><p> My very intention in a previous note of one’s "statistical significance was that a such figure may barely engender any practical values. For example, given one’s claim that "you’ll get full should you eat that much", after a series of qualifying studies, the findings evidence that the statement is true, we thereby concur that it is de facto "statistically significant".</p><p> Even though statistical results may indeed offer some practical significance, this is deemed one-hundred-to-one. Given the host of daily-basis research and scientific statistics, and that most of which often home in trivial problems within no less limited scopes, researchers’ initial goals should be to offer some statistical significance before any practically sounding, world-changing findings. Every so often, these only bring about as trivial changes. Without the research context, they, thus, are vain and no less deceptive.</p><p> For example, in the ubiquitous "toothpaste helps whiten teeth" experiment, researchers are only required to prove changes, given toothpaste as the catalyst, to the test subjects, even when such findings inflict no visual effect to the bare, human eyes. Likewise, a study on "baldness medicine" should zero in evidencing the recoverability of bald areas to barely earn itself some "statistical significance". Even though neither of which would be applicable in reality.</p><p> Statistical significance’s application, thus, is often to represent probability, while practical significance is, on the other hand, what indeed evidences the utilization of any study/figure. The media and companies, in this manner, often label certain products as "statistically significant" without further explanation, to literally defraud customers.</p><p> d) Other shades of fallacies and exploitation</p><p> "Loaded questions" [6] is the leverage of non-neutral questions in maneuvering final responses. For example, a survey on Monster Box’s popularity may involve two, albeit differently sounding, similar questions:</p><p> - Would you back Monster Box in doing away with superstitions and polishing others’ science knowledge?</p><p> Or:</p><p> - Would you back Monster Box's swatting at fields other than science?</p><p> In addition, "overgeneralization" [7] is also woefully common in drawing significant conclusions from trivial, unrepresentative samples. To demonstrate, howbeit we can conclude "dogs are four-legged animals" after having been exposed to their every branch around the grobe, it sounds no less absurd to conjecture “all dogs are white” upon seeing a whilte samoyed swarm.</p><p> Seemingly self-evident, such superficial conclusions are prevalent in painstakingly sophisticated research. For example, urban citizens are hardly emblems of the rural, nor can an adult survey somehow represent children. Since the samples, nonetheless, are kept confidential, and they appear confusing enough to morph themselves into the general “representatives” of the majority.</p><p> 2. Earn yourselves better statistical understandings</p><p> We, given our conjectures, oftentimes fill in knowledge gaps with which. For example, many exalt scientific tools so fervently that they purport that science is somehow all-powerful and always bring about accurate results.</p><p> In fact, science and the tools within are developed on the norm that rarely can we seize something in an instant. It is a system with a reliable degree of accuracy - only when people observe it from a wide enough angle, and must be extremely careful to project specifically into each study, experiment, or investigation.</p><p> Statistical probability, for example, rules that to properly and adequately survey the opinions of 100 million people is contrary to reason. The science, however, holds every method to project as little as 5,000 opinions into 100 million. To accomplish a such task, everything needs performing in accordance with the time-honored statistical probability standards. Any researcher who strictly follows the procedure, thus, earns their research the invisible watermark of "statistically significant findings in accordance with global standards".</p><p> Even though adhering to these normative systems does not necessarily propel immediate truth, it serves as the very decisive step in the modern professional science system. Hinging on its own goals, a such technique has propelled forward series after series of world-changing breakthroughs. To put into perspective, every core science in the 4.0 technology revolution thrives on a statistical probability foundation.</p><p> Nevertheless, let us not forget that statistical probability is inherently woefully convoluted, and that every relevant conclusion must come hand in hand with whatever it involves. For example, the conclusions must hail from the number of collected samples, hinged on initial presumptive statements, conducted within a well-specified environment, within a tolerable margin of error, alongside well-defined relationships.</p><p> Statistical models, after all, often lack practicality (things that de facto happen) - akin to a professional poker player who is prominent enough to calculate his winning odds, yet all too heedless that his opponents may do every trick - things that de facto oftentimes happen - behind his back. This reasons out why models, every so often, fail to accurately project reality, thereafter breeding black swans - since the latter is perennially perplexing with heaps of unanticipatable variables.</p><p> Sounds not so miraculous, eh? Yep, for the world on which you thrive is inherently constituted of such perplexing, arid, and fuddy-duddy things.</p><p> Whilst other miraculously sounding things, or the so-called bitesize knowledge pieces, statistics reveal, are by all means unearthly deceptive.</p><p> <a class="_58cn" href="/hashtag/monsterbox?__eep__=6&amp;source=feed_text&amp;epa=HASHTAG&amp;__xts__%5B0%5D=68.ARBFWJYk47QkgzW0LdtngXFh9Uoak5DY2yrMUvQmKlsuS5xvP3yC0EPgAe5u7jHe50T5Pc0VOSx-OQ-vneA80kqs77syUGGKbDwwQIFaB0jQjdGvJboXswO3qNugbNv0ABjrQIzZgEFfRGxCXbk75O2yQ4-tJCcpbvX-lUgQ9ukukxehHl_tUCFNndwZObNqSvSe4_GjnIeva0JcMCHI06F7rGwhil5h3xNNe9WRJt6aDqixvzcmt03zWomGdSOAPxMbR13Vpm59qq-cGiXflGMmOofOvB28zV2vIQ9wE7xAxIHUjeu6o8g&amp;__tn__=%2ANK-R" data-ft="{&quot;type&quot;:104,&quot;tn&quot;:&quot;*N&quot;}"><span class="_5afx"><span aria-label="hashtag" class="_58cl _5afz">#</span><span class="_58cm">MonsterBox</span></span></a></p><p> - Artist: Sam.<br> - Trans: Heinous.</p>